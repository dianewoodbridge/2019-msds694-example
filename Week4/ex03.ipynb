{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate()\n",
    "file_name = \"../Data/README.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = sc.textFile(file_name).flatMap(lambda x : x.split(\" \"))\n",
    "word_rdd = word.map(lambda x : (x,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#', 1), ('Apache', 1), ('Spark', 1), ('', 1), ('Spark', 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_rdd.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate key-value pairs of (Word, Total Occurrence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_word_rdd = word_rdd.groupByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('#', <pyspark.resultiterable.ResultIterable at 0x11731b610>),\n",
       "  ('Apache', <pyspark.resultiterable.ResultIterable at 0x11731b710>),\n",
       "  ('Spark', <pyspark.resultiterable.ResultIterable at 0x11731b790>),\n",
       "  ('', <pyspark.resultiterable.ResultIterable at 0x11731b7d0>),\n",
       "  ('is', <pyspark.resultiterable.ResultIterable at 0x11731b850>),\n",
       "  ('It', <pyspark.resultiterable.ResultIterable at 0x11731b8d0>),\n",
       "  ('provides', <pyspark.resultiterable.ResultIterable at 0x11731b950>),\n",
       "  ('high-level', <pyspark.resultiterable.ResultIterable at 0x11731b9d0>),\n",
       "  ('APIs', <pyspark.resultiterable.ResultIterable at 0x11731ba50>),\n",
       "  ('in', <pyspark.resultiterable.ResultIterable at 0x11731bad0>),\n",
       "  ('Scala,', <pyspark.resultiterable.ResultIterable at 0x11731bb50>),\n",
       "  ('Java,', <pyspark.resultiterable.ResultIterable at 0x11731bbd0>),\n",
       "  ('an', <pyspark.resultiterable.ResultIterable at 0x11731bc50>),\n",
       "  ('optimized', <pyspark.resultiterable.ResultIterable at 0x11731bd10>),\n",
       "  ('engine', <pyspark.resultiterable.ResultIterable at 0x11731bd90>),\n",
       "  ('supports', <pyspark.resultiterable.ResultIterable at 0x11731be10>),\n",
       "  ('computation', <pyspark.resultiterable.ResultIterable at 0x11731be90>),\n",
       "  ('analysis.', <pyspark.resultiterable.ResultIterable at 0x11731bf10>),\n",
       "  ('set', <pyspark.resultiterable.ResultIterable at 0x11731bf90>),\n",
       "  ('of', <pyspark.resultiterable.ResultIterable at 0x11730e050>),\n",
       "  ('tools', <pyspark.resultiterable.ResultIterable at 0x11730e110>),\n",
       "  ('SQL', <pyspark.resultiterable.ResultIterable at 0x11730e190>),\n",
       "  ('MLlib', <pyspark.resultiterable.ResultIterable at 0x11730e210>),\n",
       "  ('machine', <pyspark.resultiterable.ResultIterable at 0x11730e290>),\n",
       "  ('learning,', <pyspark.resultiterable.ResultIterable at 0x11730e310>),\n",
       "  ('GraphX', <pyspark.resultiterable.ResultIterable at 0x11730e390>),\n",
       "  ('graph', <pyspark.resultiterable.ResultIterable at 0x11730e410>),\n",
       "  ('processing,', <pyspark.resultiterable.ResultIterable at 0x11730e490>),\n",
       "  ('Documentation', <pyspark.resultiterable.ResultIterable at 0x11730e510>),\n",
       "  ('latest', <pyspark.resultiterable.ResultIterable at 0x11730e590>),\n",
       "  ('programming', <pyspark.resultiterable.ResultIterable at 0x11730e610>),\n",
       "  ('guide,', <pyspark.resultiterable.ResultIterable at 0x11730e690>),\n",
       "  ('[project', <pyspark.resultiterable.ResultIterable at 0x11730e710>),\n",
       "  ('README', <pyspark.resultiterable.ResultIterable at 0x11730e790>),\n",
       "  ('only', <pyspark.resultiterable.ResultIterable at 0x11730e810>),\n",
       "  ('basic', <pyspark.resultiterable.ResultIterable at 0x11730e890>),\n",
       "  ('instructions.', <pyspark.resultiterable.ResultIterable at 0x11730e910>),\n",
       "  ('Building', <pyspark.resultiterable.ResultIterable at 0x11730e990>),\n",
       "  ('using', <pyspark.resultiterable.ResultIterable at 0x11730ea10>),\n",
       "  ('[Apache', <pyspark.resultiterable.ResultIterable at 0x11730ead0>),\n",
       "  ('run:', <pyspark.resultiterable.ResultIterable at 0x11730eb50>),\n",
       "  ('do', <pyspark.resultiterable.ResultIterable at 0x11730ebd0>),\n",
       "  ('this', <pyspark.resultiterable.ResultIterable at 0x11730ec50>),\n",
       "  ('downloaded', <pyspark.resultiterable.ResultIterable at 0x11730ecd0>),\n",
       "  ('more', <pyspark.resultiterable.ResultIterable at 0x11730ed50>),\n",
       "  ('than', <pyspark.resultiterable.ResultIterable at 0x11730edd0>),\n",
       "  ('-T', <pyspark.resultiterable.ResultIterable at 0x11730ee50>),\n",
       "  ('Maven', <pyspark.resultiterable.ResultIterable at 0x11730eed0>),\n",
       "  ('3\"](https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3).',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x11730ef10>),\n",
       "  ('documentation', <pyspark.resultiterable.ResultIterable at 0x11730ef90>),\n",
       "  ('project', <pyspark.resultiterable.ResultIterable at 0x117321050>),\n",
       "  ('site,', <pyspark.resultiterable.ResultIterable at 0x1173210d0>),\n",
       "  ('at', <pyspark.resultiterable.ResultIterable at 0x117321150>),\n",
       "  ('Spark\"](http://spark.apache.org/docs/latest/building-spark.html).',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x117321190>),\n",
       "  ('developing', <pyspark.resultiterable.ResultIterable at 0x117321210>),\n",
       "  ('IDE,', <pyspark.resultiterable.ResultIterable at 0x117321290>),\n",
       "  ('Interactive', <pyspark.resultiterable.ResultIterable at 0x117321310>),\n",
       "  ('Shell', <pyspark.resultiterable.ResultIterable at 0x117321390>),\n",
       "  ('The', <pyspark.resultiterable.ResultIterable at 0x117321410>),\n",
       "  ('way', <pyspark.resultiterable.ResultIterable at 0x117321490>),\n",
       "  ('start', <pyspark.resultiterable.ResultIterable at 0x117321510>),\n",
       "  ('Try', <pyspark.resultiterable.ResultIterable at 0x117321590>),\n",
       "  ('following', <pyspark.resultiterable.ResultIterable at 0x117321610>),\n",
       "  ('1000:', <pyspark.resultiterable.ResultIterable at 0x117321690>),\n",
       "  ('scala>', <pyspark.resultiterable.ResultIterable at 0x117321710>),\n",
       "  ('1000).count()', <pyspark.resultiterable.ResultIterable at 0x117321790>),\n",
       "  ('Python', <pyspark.resultiterable.ResultIterable at 0x117321810>),\n",
       "  ('Alternatively,', <pyspark.resultiterable.ResultIterable at 0x117321890>),\n",
       "  ('use', <pyspark.resultiterable.ResultIterable at 0x117321910>),\n",
       "  ('And', <pyspark.resultiterable.ResultIterable at 0x117321990>),\n",
       "  ('run', <pyspark.resultiterable.ResultIterable at 0x117321a10>),\n",
       "  ('Example', <pyspark.resultiterable.ResultIterable at 0x117321a90>),\n",
       "  ('several', <pyspark.resultiterable.ResultIterable at 0x117321b10>),\n",
       "  ('programs', <pyspark.resultiterable.ResultIterable at 0x117321b90>),\n",
       "  ('them,', <pyspark.resultiterable.ResultIterable at 0x117321c10>),\n",
       "  ('`./bin/run-example',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x117321c50>),\n",
       "  ('[params]`.', <pyspark.resultiterable.ResultIterable at 0x117321cd0>),\n",
       "  ('example:', <pyspark.resultiterable.ResultIterable at 0x117321d50>),\n",
       "  ('./bin/run-example',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x117321d90>),\n",
       "  ('SparkPi', <pyspark.resultiterable.ResultIterable at 0x117321e10>),\n",
       "  ('variable', <pyspark.resultiterable.ResultIterable at 0x117321e90>),\n",
       "  ('when', <pyspark.resultiterable.ResultIterable at 0x117321f10>),\n",
       "  ('examples', <pyspark.resultiterable.ResultIterable at 0x117321f90>),\n",
       "  ('spark://', <pyspark.resultiterable.ResultIterable at 0x117327050>),\n",
       "  ('URL,', <pyspark.resultiterable.ResultIterable at 0x1173270d0>),\n",
       "  ('YARN,', <pyspark.resultiterable.ResultIterable at 0x117327150>),\n",
       "  ('\"local\"', <pyspark.resultiterable.ResultIterable at 0x1173271d0>),\n",
       "  ('locally', <pyspark.resultiterable.ResultIterable at 0x117327250>),\n",
       "  ('N', <pyspark.resultiterable.ResultIterable at 0x117327290>),\n",
       "  ('abbreviated', <pyspark.resultiterable.ResultIterable at 0x117327310>),\n",
       "  ('class', <pyspark.resultiterable.ResultIterable at 0x117327390>),\n",
       "  ('name', <pyspark.resultiterable.ResultIterable at 0x117327410>),\n",
       "  ('package.', <pyspark.resultiterable.ResultIterable at 0x117327490>),\n",
       "  ('instance:', <pyspark.resultiterable.ResultIterable at 0x117327510>),\n",
       "  ('print', <pyspark.resultiterable.ResultIterable at 0x117327590>),\n",
       "  ('usage', <pyspark.resultiterable.ResultIterable at 0x117327610>),\n",
       "  ('help', <pyspark.resultiterable.ResultIterable at 0x117327690>),\n",
       "  ('no', <pyspark.resultiterable.ResultIterable at 0x117327710>),\n",
       "  ('params', <pyspark.resultiterable.ResultIterable at 0x117327790>),\n",
       "  ('are', <pyspark.resultiterable.ResultIterable at 0x117327810>),\n",
       "  ('Testing', <pyspark.resultiterable.ResultIterable at 0x117327890>),\n",
       "  ('Spark](#building-spark).',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x1173278d0>),\n",
       "  ('Once', <pyspark.resultiterable.ResultIterable at 0x117327950>),\n",
       "  ('built,', <pyspark.resultiterable.ResultIterable at 0x11731b4d0>),\n",
       "  ('tests', <pyspark.resultiterable.ResultIterable at 0x11731b3d0>),\n",
       "  ('using:', <pyspark.resultiterable.ResultIterable at 0x11731b310>),\n",
       "  ('./dev/run-tests', <pyspark.resultiterable.ResultIterable at 0x11731b2d0>),\n",
       "  ('Please', <pyspark.resultiterable.ResultIterable at 0x11731b090>),\n",
       "  ('guidance', <pyspark.resultiterable.ResultIterable at 0x11731b390>),\n",
       "  ('module,', <pyspark.resultiterable.ResultIterable at 0x11730b650>),\n",
       "  ('individual', <pyspark.resultiterable.ResultIterable at 0x11730bd90>),\n",
       "  ('Note', <pyspark.resultiterable.ResultIterable at 0x11730bfd0>),\n",
       "  ('About', <pyspark.resultiterable.ResultIterable at 0x11730b350>),\n",
       "  ('uses', <pyspark.resultiterable.ResultIterable at 0x11730bdd0>),\n",
       "  ('library', <pyspark.resultiterable.ResultIterable at 0x11730bf50>),\n",
       "  ('HDFS', <pyspark.resultiterable.ResultIterable at 0x11730b450>),\n",
       "  ('other', <pyspark.resultiterable.ResultIterable at 0x1172b5850>),\n",
       "  ('Hadoop-supported', <pyspark.resultiterable.ResultIterable at 0x1172b5190>),\n",
       "  ('storage', <pyspark.resultiterable.ResultIterable at 0x1172b5e50>),\n",
       "  ('systems.', <pyspark.resultiterable.ResultIterable at 0x1172b5310>),\n",
       "  ('Because', <pyspark.resultiterable.ResultIterable at 0x1172b5c90>),\n",
       "  ('have', <pyspark.resultiterable.ResultIterable at 0x1172b5610>),\n",
       "  ('changed', <pyspark.resultiterable.ResultIterable at 0x1172b5b50>),\n",
       "  ('different', <pyspark.resultiterable.ResultIterable at 0x1172b5550>),\n",
       "  ('versions', <pyspark.resultiterable.ResultIterable at 0x1172b5790>),\n",
       "  ('Hadoop,', <pyspark.resultiterable.ResultIterable at 0x1172b51d0>),\n",
       "  ('must', <pyspark.resultiterable.ResultIterable at 0x1172b5b90>),\n",
       "  ('against', <pyspark.resultiterable.ResultIterable at 0x1172b5c50>),\n",
       "  ('version', <pyspark.resultiterable.ResultIterable at 0x1172b5750>),\n",
       "  ('refer', <pyspark.resultiterable.ResultIterable at 0x1172b5910>),\n",
       "  ('particular', <pyspark.resultiterable.ResultIterable at 0x1172b5510>),\n",
       "  ('distribution', <pyspark.resultiterable.ResultIterable at 0x1172b5b10>),\n",
       "  ('Hive', <pyspark.resultiterable.ResultIterable at 0x1172b5ed0>),\n",
       "  ('Thriftserver', <pyspark.resultiterable.ResultIterable at 0x1172b5650>),\n",
       "  ('distributions.', <pyspark.resultiterable.ResultIterable at 0x1172b5d10>),\n",
       "  ('[Configuration', <pyspark.resultiterable.ResultIterable at 0x117290c90>),\n",
       "  ('Guide](http://spark.apache.org/docs/latest/configuration.html)',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x117290a10>),\n",
       "  ('online', <pyspark.resultiterable.ResultIterable at 0x117290990>),\n",
       "  ('overview', <pyspark.resultiterable.ResultIterable at 0x1172a6590>),\n",
       "  ('configure', <pyspark.resultiterable.ResultIterable at 0x1172a6a90>),\n",
       "  ('Spark.', <pyspark.resultiterable.ResultIterable at 0x1172a6c50>)],\n",
       " [('a', <pyspark.resultiterable.ResultIterable at 0x11731b250>),\n",
       "  ('fast', <pyspark.resultiterable.ResultIterable at 0x1172a6dd0>),\n",
       "  ('and', <pyspark.resultiterable.ResultIterable at 0x1172a6750>),\n",
       "  ('general', <pyspark.resultiterable.ResultIterable at 0x1172a6550>),\n",
       "  ('cluster', <pyspark.resultiterable.ResultIterable at 0x11727bad0>),\n",
       "  ('computing', <pyspark.resultiterable.ResultIterable at 0x11727b5d0>),\n",
       "  ('system', <pyspark.resultiterable.ResultIterable at 0x11727bbd0>),\n",
       "  ('for', <pyspark.resultiterable.ResultIterable at 0x1172c1dd0>),\n",
       "  ('Big', <pyspark.resultiterable.ResultIterable at 0x1172c1190>),\n",
       "  ('Data.', <pyspark.resultiterable.ResultIterable at 0x1172c1290>),\n",
       "  ('Python,', <pyspark.resultiterable.ResultIterable at 0x1172c1d90>),\n",
       "  ('R,', <pyspark.resultiterable.ResultIterable at 0x1172c1910>),\n",
       "  ('that', <pyspark.resultiterable.ResultIterable at 0x1172c1b50>),\n",
       "  ('graphs', <pyspark.resultiterable.ResultIterable at 0x1172c1510>),\n",
       "  ('data', <pyspark.resultiterable.ResultIterable at 0x1172c15d0>),\n",
       "  ('also', <pyspark.resultiterable.ResultIterable at 0x1172c1990>),\n",
       "  ('rich', <pyspark.resultiterable.ResultIterable at 0x1172c18d0>),\n",
       "  ('higher-level', <pyspark.resultiterable.ResultIterable at 0x1172c1610>),\n",
       "  ('including', <pyspark.resultiterable.ResultIterable at 0x1172c1c10>),\n",
       "  ('DataFrames,', <pyspark.resultiterable.ResultIterable at 0x1172c1b10>),\n",
       "  ('Streaming', <pyspark.resultiterable.ResultIterable at 0x1172c16d0>),\n",
       "  ('stream', <pyspark.resultiterable.ResultIterable at 0x11716d290>),\n",
       "  ('processing.', <pyspark.resultiterable.ResultIterable at 0x10e9ce550>),\n",
       "  ('<http://spark.apache.org/>',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x10e9ce4d0>),\n",
       "  ('##', <pyspark.resultiterable.ResultIterable at 0x10cf6f450>),\n",
       "  ('Online', <pyspark.resultiterable.ResultIterable at 0x10fec8590>),\n",
       "  ('You', <pyspark.resultiterable.ResultIterable at 0x1172c3410>),\n",
       "  ('can', <pyspark.resultiterable.ResultIterable at 0x1172c3310>),\n",
       "  ('find', <pyspark.resultiterable.ResultIterable at 0x1172c34d0>),\n",
       "  ('the', <pyspark.resultiterable.ResultIterable at 0x1172c3250>),\n",
       "  ('documentation,', <pyspark.resultiterable.ResultIterable at 0x10e7fce10>),\n",
       "  ('on', <pyspark.resultiterable.ResultIterable at 0x117286cd0>),\n",
       "  ('web', <pyspark.resultiterable.ResultIterable at 0x117305a50>),\n",
       "  ('page](http://spark.apache.org/documentation.html)',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x117305a90>),\n",
       "  ('wiki](https://cwiki.apache.org/confluence/display/SPARK).',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x117305f50>),\n",
       "  ('This', <pyspark.resultiterable.ResultIterable at 0x117305e90>),\n",
       "  ('file', <pyspark.resultiterable.ResultIterable at 0x117305d90>),\n",
       "  ('contains', <pyspark.resultiterable.ResultIterable at 0x117305b50>),\n",
       "  ('setup', <pyspark.resultiterable.ResultIterable at 0x117305c10>),\n",
       "  ('built', <pyspark.resultiterable.ResultIterable at 0x117305990>),\n",
       "  ('Maven](http://maven.apache.org/).',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x117305b90>),\n",
       "  ('To', <pyspark.resultiterable.ResultIterable at 0x117305bd0>),\n",
       "  ('build', <pyspark.resultiterable.ResultIterable at 0x117305b10>),\n",
       "  ('its', <pyspark.resultiterable.ResultIterable at 0x117305a10>),\n",
       "  ('example', <pyspark.resultiterable.ResultIterable at 0x117305e10>),\n",
       "  ('programs,', <pyspark.resultiterable.ResultIterable at 0x1173279d0>),\n",
       "  ('build/mvn', <pyspark.resultiterable.ResultIterable at 0x117327a50>),\n",
       "  ('-DskipTests', <pyspark.resultiterable.ResultIterable at 0x117327ad0>),\n",
       "  ('clean', <pyspark.resultiterable.ResultIterable at 0x117327b50>),\n",
       "  ('package', <pyspark.resultiterable.ResultIterable at 0x117327bd0>),\n",
       "  ('(You', <pyspark.resultiterable.ResultIterable at 0x117327c50>),\n",
       "  ('not', <pyspark.resultiterable.ResultIterable at 0x117327cd0>),\n",
       "  ('need', <pyspark.resultiterable.ResultIterable at 0x117327d50>),\n",
       "  ('to', <pyspark.resultiterable.ResultIterable at 0x117327dd0>),\n",
       "  ('if', <pyspark.resultiterable.ResultIterable at 0x117327e50>),\n",
       "  ('you', <pyspark.resultiterable.ResultIterable at 0x117327f10>),\n",
       "  ('pre-built', <pyspark.resultiterable.ResultIterable at 0x117327fd0>),\n",
       "  ('package.)', <pyspark.resultiterable.ResultIterable at 0x11732b090>),\n",
       "  ('one', <pyspark.resultiterable.ResultIterable at 0x11732b110>),\n",
       "  ('thread', <pyspark.resultiterable.ResultIterable at 0x11732b190>),\n",
       "  ('by', <pyspark.resultiterable.ResultIterable at 0x11732b210>),\n",
       "  ('option', <pyspark.resultiterable.ResultIterable at 0x11732b290>),\n",
       "  ('with', <pyspark.resultiterable.ResultIterable at 0x11732b310>),\n",
       "  ('Maven,', <pyspark.resultiterable.ResultIterable at 0x11732b3d0>),\n",
       "  ('see', <pyspark.resultiterable.ResultIterable at 0x11732b450>),\n",
       "  ('[\"Parallel', <pyspark.resultiterable.ResultIterable at 0x11732b4d0>),\n",
       "  ('builds', <pyspark.resultiterable.ResultIterable at 0x11732b550>),\n",
       "  ('More', <pyspark.resultiterable.ResultIterable at 0x11732b5d0>),\n",
       "  ('detailed', <pyspark.resultiterable.ResultIterable at 0x11732b650>),\n",
       "  ('available', <pyspark.resultiterable.ResultIterable at 0x11732b6d0>),\n",
       "  ('from', <pyspark.resultiterable.ResultIterable at 0x11732b750>),\n",
       "  ('[\"Building', <pyspark.resultiterable.ResultIterable at 0x11732b7d0>),\n",
       "  ('For', <pyspark.resultiterable.ResultIterable at 0x11732b850>),\n",
       "  ('[Eclipse](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-Eclipse)',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x11732b890>),\n",
       "  ('[IntelliJ](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-IntelliJ).',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x11732b8d0>),\n",
       "  ('Scala', <pyspark.resultiterable.ResultIterable at 0x11732b950>),\n",
       "  ('easiest', <pyspark.resultiterable.ResultIterable at 0x11732b9d0>),\n",
       "  ('through', <pyspark.resultiterable.ResultIterable at 0x11732ba50>),\n",
       "  ('shell:', <pyspark.resultiterable.ResultIterable at 0x11732bad0>),\n",
       "  ('./bin/spark-shell',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x11732bb10>),\n",
       "  ('command,', <pyspark.resultiterable.ResultIterable at 0x11732bb90>),\n",
       "  ('which', <pyspark.resultiterable.ResultIterable at 0x11732bc10>),\n",
       "  ('should', <pyspark.resultiterable.ResultIterable at 0x11732bc90>),\n",
       "  ('return', <pyspark.resultiterable.ResultIterable at 0x11732bd10>),\n",
       "  ('sc.parallelize(1', <pyspark.resultiterable.ResultIterable at 0x11732bd50>),\n",
       "  ('prefer', <pyspark.resultiterable.ResultIterable at 0x11732bdd0>),\n",
       "  ('./bin/pyspark', <pyspark.resultiterable.ResultIterable at 0x11732be50>),\n",
       "  ('>>>', <pyspark.resultiterable.ResultIterable at 0x11732bed0>),\n",
       "  ('sc.parallelize(range(1000)).count()',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x11732bf10>),\n",
       "  ('Programs', <pyspark.resultiterable.ResultIterable at 0x11732bf90>),\n",
       "  ('comes', <pyspark.resultiterable.ResultIterable at 0x11732d050>),\n",
       "  ('sample', <pyspark.resultiterable.ResultIterable at 0x11732d0d0>),\n",
       "  ('`examples`', <pyspark.resultiterable.ResultIterable at 0x11732d150>),\n",
       "  ('directory.', <pyspark.resultiterable.ResultIterable at 0x11732d1d0>),\n",
       "  ('<class>', <pyspark.resultiterable.ResultIterable at 0x11732d250>),\n",
       "  ('will', <pyspark.resultiterable.ResultIterable at 0x11732d2d0>),\n",
       "  ('Pi', <pyspark.resultiterable.ResultIterable at 0x11732d350>),\n",
       "  ('locally.', <pyspark.resultiterable.ResultIterable at 0x11732d3d0>),\n",
       "  ('MASTER', <pyspark.resultiterable.ResultIterable at 0x11732d450>),\n",
       "  ('environment', <pyspark.resultiterable.ResultIterable at 0x11732d4d0>),\n",
       "  ('running', <pyspark.resultiterable.ResultIterable at 0x11732d550>),\n",
       "  ('submit', <pyspark.resultiterable.ResultIterable at 0x11732d5d0>),\n",
       "  ('cluster.', <pyspark.resultiterable.ResultIterable at 0x11732d650>),\n",
       "  ('be', <pyspark.resultiterable.ResultIterable at 0x11732d6d0>),\n",
       "  ('mesos://', <pyspark.resultiterable.ResultIterable at 0x11732d750>),\n",
       "  ('or', <pyspark.resultiterable.ResultIterable at 0x11732d7d0>),\n",
       "  ('\"yarn\"', <pyspark.resultiterable.ResultIterable at 0x11732d850>),\n",
       "  ('thread,', <pyspark.resultiterable.ResultIterable at 0x11732d8d0>),\n",
       "  ('\"local[N]\"', <pyspark.resultiterable.ResultIterable at 0x11732d950>),\n",
       "  ('threads.', <pyspark.resultiterable.ResultIterable at 0x11732d9d0>),\n",
       "  ('MASTER=spark://host:7077',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x11732da10>),\n",
       "  ('Many', <pyspark.resultiterable.ResultIterable at 0x11732da90>),\n",
       "  ('given.', <pyspark.resultiterable.ResultIterable at 0x11732db10>),\n",
       "  ('Running', <pyspark.resultiterable.ResultIterable at 0x11732db90>),\n",
       "  ('Tests', <pyspark.resultiterable.ResultIterable at 0x11732dc10>),\n",
       "  ('first', <pyspark.resultiterable.ResultIterable at 0x11732dc90>),\n",
       "  ('requires', <pyspark.resultiterable.ResultIterable at 0x11732dd10>),\n",
       "  ('[building', <pyspark.resultiterable.ResultIterable at 0x11732dd90>),\n",
       "  ('how', <pyspark.resultiterable.ResultIterable at 0x11732de10>),\n",
       "  ('[run', <pyspark.resultiterable.ResultIterable at 0x11732de90>),\n",
       "  ('tests](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools).',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x11732ded0>),\n",
       "  ('A', <pyspark.resultiterable.ResultIterable at 0x11732df10>),\n",
       "  ('Hadoop', <pyspark.resultiterable.ResultIterable at 0x11732df90>),\n",
       "  ('Versions', <pyspark.resultiterable.ResultIterable at 0x117330050>),\n",
       "  ('core', <pyspark.resultiterable.ResultIterable at 0x1173300d0>),\n",
       "  ('talk', <pyspark.resultiterable.ResultIterable at 0x117330150>),\n",
       "  ('protocols', <pyspark.resultiterable.ResultIterable at 0x1173301d0>),\n",
       "  ('same', <pyspark.resultiterable.ResultIterable at 0x117330250>),\n",
       "  ('your', <pyspark.resultiterable.ResultIterable at 0x1173302d0>),\n",
       "  ('runs.', <pyspark.resultiterable.ResultIterable at 0x117330350>),\n",
       "  ('[\"Specifying', <pyspark.resultiterable.ResultIterable at 0x1173303d0>),\n",
       "  ('Version\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)',\n",
       "   <pyspark.resultiterable.ResultIterable at 0x117330410>),\n",
       "  ('building', <pyspark.resultiterable.ResultIterable at 0x117330490>),\n",
       "  ('Configuration', <pyspark.resultiterable.ResultIterable at 0x117330510>)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_word_rdd.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = grouped_word_rdd.mapValues(lambda x : sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('#', 1),\n",
       "  ('Apache', 1),\n",
       "  ('Spark', 15),\n",
       "  ('', 68),\n",
       "  ('is', 6),\n",
       "  ('It', 2),\n",
       "  ('provides', 1),\n",
       "  ('high-level', 1),\n",
       "  ('APIs', 1),\n",
       "  ('in', 6),\n",
       "  ('Scala,', 1),\n",
       "  ('Java,', 1),\n",
       "  ('an', 4),\n",
       "  ('optimized', 1),\n",
       "  ('engine', 1),\n",
       "  ('supports', 2),\n",
       "  ('computation', 1),\n",
       "  ('analysis.', 1),\n",
       "  ('set', 2),\n",
       "  ('of', 5),\n",
       "  ('tools', 1),\n",
       "  ('SQL', 2),\n",
       "  ('MLlib', 1),\n",
       "  ('machine', 1),\n",
       "  ('learning,', 1),\n",
       "  ('GraphX', 1),\n",
       "  ('graph', 1),\n",
       "  ('processing,', 1),\n",
       "  ('Documentation', 1),\n",
       "  ('latest', 1),\n",
       "  ('programming', 1),\n",
       "  ('guide,', 1),\n",
       "  ('[project', 2),\n",
       "  ('README', 1),\n",
       "  ('only', 1),\n",
       "  ('basic', 1),\n",
       "  ('instructions.', 1),\n",
       "  ('Building', 1),\n",
       "  ('using', 5),\n",
       "  ('[Apache', 1),\n",
       "  ('run:', 1),\n",
       "  ('do', 2),\n",
       "  ('this', 1),\n",
       "  ('downloaded', 1),\n",
       "  ('more', 1),\n",
       "  ('than', 1),\n",
       "  ('-T', 1),\n",
       "  ('Maven', 1),\n",
       "  ('3\"](https://cwiki.apache.org/confluence/display/MAVEN/Parallel+builds+in+Maven+3).',\n",
       "   1),\n",
       "  ('documentation', 3),\n",
       "  ('project', 1),\n",
       "  ('site,', 1),\n",
       "  ('at', 2),\n",
       "  ('Spark\"](http://spark.apache.org/docs/latest/building-spark.html).', 1),\n",
       "  ('developing', 1),\n",
       "  ('IDE,', 1),\n",
       "  ('Interactive', 2),\n",
       "  ('Shell', 2),\n",
       "  ('The', 1),\n",
       "  ('way', 1),\n",
       "  ('start', 1),\n",
       "  ('Try', 1),\n",
       "  ('following', 2),\n",
       "  ('1000:', 2),\n",
       "  ('scala>', 1),\n",
       "  ('1000).count()', 1),\n",
       "  ('Python', 2),\n",
       "  ('Alternatively,', 1),\n",
       "  ('use', 3),\n",
       "  ('And', 1),\n",
       "  ('run', 7),\n",
       "  ('Example', 1),\n",
       "  ('several', 1),\n",
       "  ('programs', 2),\n",
       "  ('them,', 1),\n",
       "  ('`./bin/run-example', 1),\n",
       "  ('[params]`.', 1),\n",
       "  ('example:', 1),\n",
       "  ('./bin/run-example', 2),\n",
       "  ('SparkPi', 2),\n",
       "  ('variable', 1),\n",
       "  ('when', 1),\n",
       "  ('examples', 2),\n",
       "  ('spark://', 1),\n",
       "  ('URL,', 1),\n",
       "  ('YARN,', 1),\n",
       "  ('\"local\"', 1),\n",
       "  ('locally', 2),\n",
       "  ('N', 1),\n",
       "  ('abbreviated', 1),\n",
       "  ('class', 2),\n",
       "  ('name', 1),\n",
       "  ('package.', 1),\n",
       "  ('instance:', 1),\n",
       "  ('print', 1),\n",
       "  ('usage', 1),\n",
       "  ('help', 1),\n",
       "  ('no', 1),\n",
       "  ('params', 1),\n",
       "  ('are', 1),\n",
       "  ('Testing', 1),\n",
       "  ('Spark](#building-spark).', 1),\n",
       "  ('Once', 1),\n",
       "  ('built,', 1),\n",
       "  ('tests', 2),\n",
       "  ('using:', 1),\n",
       "  ('./dev/run-tests', 1),\n",
       "  ('Please', 3),\n",
       "  ('guidance', 2),\n",
       "  ('module,', 1),\n",
       "  ('individual', 1),\n",
       "  ('Note', 1),\n",
       "  ('About', 1),\n",
       "  ('uses', 1),\n",
       "  ('library', 1),\n",
       "  ('HDFS', 1),\n",
       "  ('other', 1),\n",
       "  ('Hadoop-supported', 1),\n",
       "  ('storage', 1),\n",
       "  ('systems.', 1),\n",
       "  ('Because', 1),\n",
       "  ('have', 1),\n",
       "  ('changed', 1),\n",
       "  ('different', 1),\n",
       "  ('versions', 1),\n",
       "  ('Hadoop,', 2),\n",
       "  ('must', 1),\n",
       "  ('against', 1),\n",
       "  ('version', 1),\n",
       "  ('refer', 2),\n",
       "  ('particular', 2),\n",
       "  ('distribution', 1),\n",
       "  ('Hive', 2),\n",
       "  ('Thriftserver', 1),\n",
       "  ('distributions.', 1),\n",
       "  ('[Configuration', 1),\n",
       "  ('Guide](http://spark.apache.org/docs/latest/configuration.html)', 1),\n",
       "  ('online', 1),\n",
       "  ('overview', 1),\n",
       "  ('configure', 1),\n",
       "  ('Spark.', 1)],\n",
       " [('a', 8),\n",
       "  ('fast', 1),\n",
       "  ('and', 11),\n",
       "  ('general', 2),\n",
       "  ('cluster', 2),\n",
       "  ('computing', 1),\n",
       "  ('system', 1),\n",
       "  ('for', 11),\n",
       "  ('Big', 1),\n",
       "  ('Data.', 1),\n",
       "  ('Python,', 2),\n",
       "  ('R,', 1),\n",
       "  ('that', 2),\n",
       "  ('graphs', 1),\n",
       "  ('data', 1),\n",
       "  ('also', 4),\n",
       "  ('rich', 1),\n",
       "  ('higher-level', 1),\n",
       "  ('including', 3),\n",
       "  ('DataFrames,', 1),\n",
       "  ('Streaming', 1),\n",
       "  ('stream', 1),\n",
       "  ('processing.', 1),\n",
       "  ('<http://spark.apache.org/>', 1),\n",
       "  ('##', 8),\n",
       "  ('Online', 1),\n",
       "  ('You', 4),\n",
       "  ('can', 7),\n",
       "  ('find', 1),\n",
       "  ('the', 22),\n",
       "  ('documentation,', 1),\n",
       "  ('on', 5),\n",
       "  ('web', 1),\n",
       "  ('page](http://spark.apache.org/documentation.html)', 1),\n",
       "  ('wiki](https://cwiki.apache.org/confluence/display/SPARK).', 1),\n",
       "  ('This', 2),\n",
       "  ('file', 1),\n",
       "  ('contains', 1),\n",
       "  ('setup', 1),\n",
       "  ('built', 1),\n",
       "  ('Maven](http://maven.apache.org/).', 1),\n",
       "  ('To', 2),\n",
       "  ('build', 4),\n",
       "  ('its', 1),\n",
       "  ('example', 3),\n",
       "  ('programs,', 1),\n",
       "  ('build/mvn', 1),\n",
       "  ('-DskipTests', 1),\n",
       "  ('clean', 1),\n",
       "  ('package', 1),\n",
       "  ('(You', 1),\n",
       "  ('not', 1),\n",
       "  ('need', 1),\n",
       "  ('to', 14),\n",
       "  ('if', 4),\n",
       "  ('you', 4),\n",
       "  ('pre-built', 1),\n",
       "  ('package.)', 1),\n",
       "  ('one', 3),\n",
       "  ('thread', 1),\n",
       "  ('by', 1),\n",
       "  ('option', 1),\n",
       "  ('with', 4),\n",
       "  ('Maven,', 1),\n",
       "  ('see', 3),\n",
       "  ('[\"Parallel', 1),\n",
       "  ('builds', 1),\n",
       "  ('More', 1),\n",
       "  ('detailed', 2),\n",
       "  ('available', 1),\n",
       "  ('from', 1),\n",
       "  ('[\"Building', 1),\n",
       "  ('For', 3),\n",
       "  ('[Eclipse](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-Eclipse)',\n",
       "   1),\n",
       "  ('[IntelliJ](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools#UsefulDeveloperTools-IntelliJ).',\n",
       "   1),\n",
       "  ('Scala', 2),\n",
       "  ('easiest', 1),\n",
       "  ('through', 1),\n",
       "  ('shell:', 2),\n",
       "  ('./bin/spark-shell', 1),\n",
       "  ('command,', 2),\n",
       "  ('which', 2),\n",
       "  ('should', 2),\n",
       "  ('return', 2),\n",
       "  ('sc.parallelize(1', 1),\n",
       "  ('prefer', 1),\n",
       "  ('./bin/pyspark', 1),\n",
       "  ('>>>', 1),\n",
       "  ('sc.parallelize(range(1000)).count()', 1),\n",
       "  ('Programs', 1),\n",
       "  ('comes', 1),\n",
       "  ('sample', 1),\n",
       "  ('`examples`', 2),\n",
       "  ('directory.', 1),\n",
       "  ('<class>', 1),\n",
       "  ('will', 1),\n",
       "  ('Pi', 1),\n",
       "  ('locally.', 1),\n",
       "  ('MASTER', 1),\n",
       "  ('environment', 1),\n",
       "  ('running', 1),\n",
       "  ('submit', 1),\n",
       "  ('cluster.', 1),\n",
       "  ('be', 2),\n",
       "  ('mesos://', 1),\n",
       "  ('or', 3),\n",
       "  ('\"yarn\"', 1),\n",
       "  ('thread,', 1),\n",
       "  ('\"local[N]\"', 1),\n",
       "  ('threads.', 1),\n",
       "  ('MASTER=spark://host:7077', 1),\n",
       "  ('Many', 1),\n",
       "  ('given.', 1),\n",
       "  ('Running', 1),\n",
       "  ('Tests', 1),\n",
       "  ('first', 1),\n",
       "  ('requires', 1),\n",
       "  ('[building', 1),\n",
       "  ('how', 2),\n",
       "  ('[run', 1),\n",
       "  ('tests](https://cwiki.apache.org/confluence/display/SPARK/Useful+Developer+Tools).',\n",
       "   1),\n",
       "  ('A', 1),\n",
       "  ('Hadoop', 3),\n",
       "  ('Versions', 1),\n",
       "  ('core', 1),\n",
       "  ('talk', 1),\n",
       "  ('protocols', 1),\n",
       "  ('same', 1),\n",
       "  ('your', 1),\n",
       "  ('runs.', 1),\n",
       "  ('[\"Specifying', 1),\n",
       "  ('Version\"](http://spark.apache.org/docs/latest/building-spark.html#specifying-the-hadoop-version)',\n",
       "   1),\n",
       "  ('building', 2),\n",
       "  ('Configuration', 1)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
